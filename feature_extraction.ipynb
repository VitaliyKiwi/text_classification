{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and feature extraction\n",
    "- Convert categorical label values into numerical values\n",
    "- Extract features from text, including converting text to numeric repricentation as vectors\n",
    "- Split data into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import scipy\n",
    "import util # the utility module contains the feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc-text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categorical label values into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(df[\"category\"])\n",
    "df['encoded_category'] = le.transform(df[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>encoded_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "   encoded_category  \n",
       "0                 4  \n",
       "1                 0  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sport'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform([3])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the encoded categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>encoded_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  encoded_category\n",
       "1       business                 0\n",
       "4  entertainment                 1\n",
       "5       politics                 2\n",
       "2          sport                 3\n",
       "0           tech                 4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['category', 'encoded_category']].drop_duplicates().sort_values('encoded_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before transform text into input features, split the sample data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['encoded_category'], test_size=.2, stratify=df['category'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first train text, show only the first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tv future in the hands of viewers with home theatre systems  plasma high-definition tvs  and digital video recorders moving into the living room  the way people watch tv will be radically different in five years  time.  that is according to an expert panel which gathered at the annual consumer electronics show in las vegas to discuss how these new technologies will impact one of our favourite pastimes. with the us leading the trend  programmes and other content will be delivered to viewers via home networks  through cable  satellite  telecoms companies  and broadband service providers to front rooms and portable devices.  one of the most talked-about technologies of ces has been digital and personal video recorders (dvr and pvr). these set-top boxes  like the us s tivo and the uk s sky+ system  allow people to record  store  play  pause and forward wind tv programmes when they want.  essentially  the technology allows for much more personalised tv. they are also being built-in to high-'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the input text using TF-IDF (term frequency-inverse document frequency) features, tf-idf provides a weight of how relavent a perticular word is to the document or text context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 26501)\n"
     ]
    }
   ],
   "source": [
    "def tfidf_transform(x_train, x_test):\n",
    "    kwargs = {\n",
    "            'ngram_range': (1,1),  # Use 1-grams + 2-grams.\n",
    "            'analyzer': 'word',  # Split text into word tokens.\n",
    "            'min_df': 1,\n",
    "            'stop_words': \"english\",\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train_transformed = vectorizer.fit_transform(x_train)\n",
    "    # Vectorize validation texts.\n",
    "    x_test_transformed = vectorizer.transform(x_test)\n",
    "    return x_train_transformed, x_test_transformed\n",
    "\n",
    "tfidf_train, tfidf_test = tfidf_transform(x_train, x_test)\n",
    "print(tfidf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check first sample data after tfidf transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09250662, 0.0604464 , 0.08807122, 0.04670963, 0.04975965,\n",
       "       0.06622331, 0.05306013, 0.0616137 , 0.04227424, 0.07514611,\n",
       "       0.04037069, 0.15099678, 0.06576305, 0.05473991, 0.09012997,\n",
       "       0.08247605, 0.01788117, 0.06669774, 0.10944471, 0.05377262,\n",
       "       0.07787397, 0.12013145, 0.08000394, 0.07019845, 0.14357862,\n",
       "       0.10116865, 0.07212817, 0.10600434, 0.0789022 , 0.07178931,\n",
       "       0.05613192, 0.0789022 , 0.08000394, 0.0811905 , 0.07644979,\n",
       "       0.05997197, 0.06384666, 0.07319189, 0.07556854, 0.08030768,\n",
       "       0.06669774, 0.0805858 , 0.08935123, 0.0953176 , 0.17084337,\n",
       "       0.11388011, 0.0550763 , 0.08906626, 0.04704264, 0.09005206,\n",
       "       0.03632227, 0.05377262, 0.05877387, 0.04684198, 0.07473494,\n",
       "       0.04232373, 0.04959988, 0.06306585, 0.14039689, 0.13084726,\n",
       "       0.06821546, 0.06903429, 0.05997197, 0.03497236, 0.05779686,\n",
       "       0.03356176, 0.04377833, 0.10992671, 0.0953176 , 0.12013145,\n",
       "       0.05806975, 0.06821546, 0.06268979, 0.07514611, 0.17813252,\n",
       "       0.14039689, 0.1261317 , 0.05589101, 0.18133919, 0.1232274 ,\n",
       "       0.13643092, 0.07113314, 0.06466913, 0.06576305, 0.05779686,\n",
       "       0.07738448, 0.08713653, 0.07178931, 0.08625528, 0.18038548,\n",
       "       0.05145562, 0.07787397, 0.54722354])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When feeding the TF-IDF encoded sparse matrix data to deep learning network, it needs to be converted back to dense matrix.\n",
    "Convert sparse matrix to dense matrix and check the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "1780\n",
      "[[0.0953176  0.0616137  0.07514611 0.05589101 0.06576305 0.03632227\n",
      "  0.54722354 0.07212817 0.09012997 0.06268979 0.0604464  0.08807122\n",
      "  0.08906626 0.05806975 0.13643092 0.07178931 0.07473494 0.18038548\n",
      "  0.10992671 0.05473991 0.05377262 0.14039689 0.05997197 0.06821546\n",
      "  0.08625528 0.05613192 0.0550763  0.04670963 0.08000394 0.06306585\n",
      "  0.17084337 0.17813252 0.07787397 0.09250662 0.06821546 0.0811905\n",
      "  0.07644979 0.07787397 0.18133919 0.05997197 0.12013145 0.07319189\n",
      "  0.08030768 0.04037069 0.04684198 0.0789022  0.06622331 0.10944471\n",
      "  0.0805858  0.1232274  0.06576305 0.04959988 0.14357862 0.06903429\n",
      "  0.05877387 0.05145562 0.06466913 0.07514611 0.09005206 0.04377833\n",
      "  0.08713653 0.05377262 0.07019845 0.04975965 0.08935123 0.04704264\n",
      "  0.15099678 0.06669774 0.10116865 0.07738448 0.05779686 0.0789022\n",
      "  0.06384666 0.01788117 0.07556854 0.07113314 0.06669774 0.10600434\n",
      "  0.08247605 0.08000394 0.11388011 0.12013145 0.0953176  0.07178931\n",
      "  0.1261317  0.05306013 0.04232373 0.14039689 0.03497236 0.05779686\n",
      "  0.13084726 0.04227424 0.03356176]]\n"
     ]
    }
   ],
   "source": [
    "train_tfidf_dense = scipy.sparse.csr_matrix.todense(tfidf_train)\n",
    "print(train_tfidf_dense[0]) # [train_tfidf_dense[0] != 0][0]\n",
    "print(len(train_tfidf_dense))\n",
    "print(train_tfidf_dense[0][train_tfidf_dense[0] != 0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another way to encode text into numeric presentation is use tokenize the text and apply padded sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_transform(x_train, x_test, vocab_size=50000, max_len=20000):\n",
    "    \"\"\"Convert input raw tests into pad sequence encoded integer matrix\n",
    "    Args:\n",
    "        x_train: array of input text, the raw input training text data\n",
    "        x_test: array of input text, the raw input test text data\n",
    "        vocab_size: maximum number of vocabulary used for tokenization\n",
    "                    default to 50000\n",
    "        max_len: maximum length of padded sequences\n",
    "                default to 20000\n",
    "    \"\"\"\n",
    "    oov_tok = '<OOV>'\n",
    "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    word_index = tokenizer.word_index\n",
    "    x_seq = tokenizer.texts_to_sequences(x_train)\n",
    "    train_padded = pad_sequences(x_seq, padding='post', maxlen=max_len)\n",
    "    test_padded = pad_sequences(tokenizer.texts_to_sequences(x_test), padding='post', maxlen=max_len)\n",
    "    return train_padded, test_padded\n",
    "\n",
    "train_padded, test_padded = pad_sequence_transform(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1780, 20000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4353, 2571,  361,  629, 3112, 1528, 3331, 4353, 2572,  653],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put the tow feature extraction functions into a util.py module so they can be call when build machine learning or deep learning models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
